Command Line Args: Namespace(config_file='configs/fsod/finetune_R_50_C4_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[32m[08/08 17:33:22 detectron2]: [0mRank of current process: 0. World size: 4
[32m[08/08 17:33:22 detectron2]: [0mEnvironment info:
----------------------  ---------------------------------------------------------------
sys.platform            linux
Python                  3.7.4 (default, Aug 13 2019, 20:35:49) [GCC 7.3.0]
numpy                   1.18.4
detectron2              0.2 @/opt/conda/lib/python3.7/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.1
detectron2 arch flags   sm_35, sm_37, sm_50, sm_52, sm_60, sm_61, sm_70, sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.5.1+cu101 @/opt/conda/lib/python3.7/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1,2,3             GeForce GTX 1080 Ti
CUDA_HOME               /usr/local/cuda
Pillow                  6.2.2
torchvision             0.6.1+cu101 @/opt/conda/lib/python3.7/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.1
cv2                     4.2.0
----------------------  ---------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2019.0.5 Product Build 20190808 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[32m[08/08 17:33:22 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/fsod/finetune_R_50_C4_1x.yaml', dist_url='tcp://127.0.0.1:49152', eval_only=False, machine_rank=0, num_gpus=4, num_machines=1, opts=[], resume=False)
[32m[08/08 17:33:22 detectron2]: [0mContents of args.config_file=configs/fsod/finetune_R_50_C4_1x.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  WEIGHTS: "./output/fsod/R_50_C4_1x/model_final.pth" 
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 5
DATASETS:
  TRAIN: ("coco_2017_train_voc_10_shot",)
  TEST: ("coco_2017_val",)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.001
  STEPS: (2000, 3000)
  MAX_ITER: 3000
  WARMUP_ITERS: 200
INPUT:
  FS:
    FEW_SHOT: True
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 9
  MIN_SIZE_TRAIN: (440, 472, 504, 536, 568, 600)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
OUTPUT_DIR: './output/fsod/finetune_dir/R_50_C4_1x'


[32m[08/08 17:33:22 detectron2]: [0mRunning with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('coco_2017_val',)
  TRAIN: ('coco_2017_train_voc_10_shot',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: True
    SUPPORT_SHOT: 9
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (440, 472, 504, 536, 568, 600)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 5
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/R_50_C4_1x/model_final.pth
OUTPUT_DIR: ./output/fsod/finetune_dir/R_50_C4_1x
SEED: -1
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 30000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (2000, 3000)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[32m[08/08 17:33:22 detectron2]: [0mFull config saved to ./output/fsod/finetune_dir/R_50_C4_1x/config.yaml
[32m[08/08 17:33:22 d2.utils.env]: [0mUsing a generated random seed 22900468
[32m[08/08 17:33:23 d2.engine.defaults]: [0mModel:
FsodRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=2048, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=2048, out_features=2, bias=True)
      (conv_cor): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=2048, out_features=2, bias=True)
      (fc_1): Linear(in_features=4096, out_features=2048, bias=True)
      (fc_2): Linear(in_features=2048, out_features=2048, bias=True)
      (cls_score_fc): Linear(in_features=2048, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[32m[08/08 17:33:24 d2.data.datasets.coco]: [0mLoaded 118287 images in COCO format from datasets/coco/new_annotations/final_split_voc_10_shot_instances_train2017.json
[32m[08/08 17:33:25 d2.data.build]: [0mRemoved 118087 images with no usable annotations. 200 images left.
[32m[08/08 17:33:25 d2.data.build]: [0mRemoved 0 images with no usable annotations. 200 images left.
[32m[08/08 17:33:25 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10           |   bicycle    | 10           |      car      | 10           |
|  motorcycle   | 10           |   airplane   | 10           |      bus      | 10           |
|     train     | 10           |    truck     | 0            |     boat      | 10           |
| traffic light | 0            | fire hydrant | 0            |   stop sign   | 0            |
| parking meter | 0            |    bench     | 0            |     bird      | 10           |
|      cat      | 10           |     dog      | 10           |     horse     | 10           |
|     sheep     | 10           |     cow      | 10           |   elephant    | 0            |
|     bear      | 0            |    zebra     | 0            |    giraffe    | 0            |
|   backpack    | 0            |   umbrella   | 0            |    handbag    | 0            |
|      tie      | 0            |   suitcase   | 0            |    frisbee    | 0            |
|     skis      | 0            |  snowboard   | 0            |  sports ball  | 0            |
|     kite      | 0            | baseball bat | 0            | baseball gl.. | 0            |
|  skateboard   | 0            |  surfboard   | 0            | tennis racket | 0            |
|    bottle     | 10           |  wine glass  | 0            |      cup      | 0            |
|     fork      | 0            |    knife     | 0            |     spoon     | 0            |
|     bowl      | 0            |    banana    | 0            |     apple     | 0            |
|   sandwich    | 0            |    orange    | 0            |   broccoli    | 0            |
|    carrot     | 0            |   hot dog    | 0            |     pizza     | 0            |
|     donut     | 0            |     cake     | 0            |     chair     | 10           |
|     couch     | 10           | potted plant | 10           |      bed      | 0            |
| dining table  | 10           |    toilet    | 0            |      tv       | 10           |
|    laptop     | 0            |    mouse     | 0            |    remote     | 0            |
|   keyboard    | 0            |  cell phone  | 0            |   microwave   | 0            |
|     oven      | 0            |   toaster    | 0            |     sink      | 0            |
| refrigerator  | 0            |     book     | 0            |     clock     | 0            |
|     vase      | 0            |   scissors   | 0            |  teddy bear   | 0            |
|  hair drier   | 0            |  toothbrush  | 0            |               |              |
|     total     | 200          |              |              |               |              |[0m
[32m[08/08 17:33:25 d2.data.common]: [0mSerializing 200 elements to byte tensors and concatenating them all ...
[32m[08/08 17:33:25 d2.data.common]: [0mSerialized dataset takes 0.05 MiB
[32m[08/08 17:33:25 fewx.data.build]: [0mUsing training sampler TrainingSampler
[32m[08/08 17:33:25 fvcore.common.checkpoint]: [0mLoading checkpoint from ./output/fsod/R_50_C4_1x/model_final.pth
[32m[08/08 17:33:26 d2.engine.train_loop]: [0mStarting training from iteration 0
[32m[08/08 17:33:50 d2.utils.events]: [0m eta: 0:19:48  iter: 19  total_loss: 0.605  loss_cls: 0.393  loss_box_reg: 0.155  loss_rpn_cls: 0.063  loss_rpn_loc: 0.012  time: 0.3985  data_time: 0.8225  lr: 0.000186  max_mem: 2011M
[32m[08/08 17:33:58 d2.utils.events]: [0m eta: 0:19:35  iter: 39  total_loss: 0.650  loss_cls: 0.388  loss_box_reg: 0.160  loss_rpn_cls: 0.066  loss_rpn_loc: 0.015  time: 0.3990  data_time: 0.0075  lr: 0.000276  max_mem: 2017M
[32m[08/08 17:34:06 d2.utils.events]: [0m eta: 0:19:29  iter: 59  total_loss: 0.534  loss_cls: 0.268  loss_box_reg: 0.158  loss_rpn_cls: 0.062  loss_rpn_loc: 0.017  time: 0.3997  data_time: 0.0076  lr: 0.000365  max_mem: 2017M
[32m[08/08 17:34:14 d2.utils.events]: [0m eta: 0:19:22  iter: 79  total_loss: 0.514  loss_cls: 0.232  loss_box_reg: 0.157  loss_rpn_cls: 0.070  loss_rpn_loc: 0.014  time: 0.3995  data_time: 0.0071  lr: 0.000456  max_mem: 2017M
[32m[08/08 17:34:22 d2.utils.events]: [0m eta: 0:19:13  iter: 99  total_loss: 0.527  loss_cls: 0.284  loss_box_reg: 0.119  loss_rpn_cls: 0.056  loss_rpn_loc: 0.015  time: 0.3995  data_time: 0.0069  lr: 0.000545  max_mem: 2017M
[32m[08/08 17:34:30 d2.utils.events]: [0m eta: 0:19:07  iter: 119  total_loss: 0.430  loss_cls: 0.211  loss_box_reg: 0.136  loss_rpn_cls: 0.074  loss_rpn_loc: 0.022  time: 0.3993  data_time: 0.0072  lr: 0.000635  max_mem: 2017M
[32m[08/08 17:34:38 d2.utils.events]: [0m eta: 0:18:59  iter: 139  total_loss: 0.451  loss_cls: 0.206  loss_box_reg: 0.143  loss_rpn_cls: 0.090  loss_rpn_loc: 0.018  time: 0.3995  data_time: 0.0071  lr: 0.000725  max_mem: 2017M
[32m[08/08 17:34:46 d2.utils.events]: [0m eta: 0:18:51  iter: 159  total_loss: 0.400  loss_cls: 0.197  loss_box_reg: 0.126  loss_rpn_cls: 0.054  loss_rpn_loc: 0.013  time: 0.3995  data_time: 0.0071  lr: 0.000816  max_mem: 2017M
[32m[08/08 17:34:54 d2.utils.events]: [0m eta: 0:18:44  iter: 179  total_loss: 0.348  loss_cls: 0.146  loss_box_reg: 0.129  loss_rpn_cls: 0.049  loss_rpn_loc: 0.010  time: 0.3994  data_time: 0.0070  lr: 0.000905  max_mem: 2017M
[32m[08/08 17:35:02 d2.utils.events]: [0m eta: 0:18:36  iter: 199  total_loss: 0.421  loss_cls: 0.160  loss_box_reg: 0.133  loss_rpn_cls: 0.084  loss_rpn_loc: 0.025  time: 0.3996  data_time: 0.0070  lr: 0.000996  max_mem: 2017M
[32m[08/08 17:35:10 d2.utils.events]: [0m eta: 0:18:28  iter: 219  total_loss: 0.351  loss_cls: 0.143  loss_box_reg: 0.126  loss_rpn_cls: 0.058  loss_rpn_loc: 0.015  time: 0.3996  data_time: 0.0074  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:35:18 d2.utils.events]: [0m eta: 0:18:20  iter: 239  total_loss: 0.382  loss_cls: 0.131  loss_box_reg: 0.126  loss_rpn_cls: 0.075  loss_rpn_loc: 0.024  time: 0.3999  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:35:26 d2.utils.events]: [0m eta: 0:18:13  iter: 259  total_loss: 0.331  loss_cls: 0.124  loss_box_reg: 0.101  loss_rpn_cls: 0.062  loss_rpn_loc: 0.016  time: 0.4000  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:35:34 d2.utils.events]: [0m eta: 0:18:05  iter: 279  total_loss: 0.273  loss_cls: 0.109  loss_box_reg: 0.104  loss_rpn_cls: 0.043  loss_rpn_loc: 0.011  time: 0.4000  data_time: 0.0065  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:35:42 d2.utils.events]: [0m eta: 0:17:57  iter: 299  total_loss: 0.317  loss_cls: 0.134  loss_box_reg: 0.125  loss_rpn_cls: 0.064  loss_rpn_loc: 0.014  time: 0.3999  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:35:50 d2.utils.events]: [0m eta: 0:17:49  iter: 319  total_loss: 0.330  loss_cls: 0.133  loss_box_reg: 0.117  loss_rpn_cls: 0.051  loss_rpn_loc: 0.012  time: 0.3999  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:35:58 d2.utils.events]: [0m eta: 0:17:41  iter: 339  total_loss: 0.297  loss_cls: 0.103  loss_box_reg: 0.101  loss_rpn_cls: 0.059  loss_rpn_loc: 0.016  time: 0.3998  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:36:06 d2.utils.events]: [0m eta: 0:17:33  iter: 359  total_loss: 0.283  loss_cls: 0.095  loss_box_reg: 0.120  loss_rpn_cls: 0.058  loss_rpn_loc: 0.019  time: 0.3999  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:36:14 d2.utils.events]: [0m eta: 0:17:25  iter: 379  total_loss: 0.292  loss_cls: 0.093  loss_box_reg: 0.113  loss_rpn_cls: 0.063  loss_rpn_loc: 0.020  time: 0.3998  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:36:22 d2.utils.events]: [0m eta: 0:17:17  iter: 399  total_loss: 0.274  loss_cls: 0.110  loss_box_reg: 0.116  loss_rpn_cls: 0.053  loss_rpn_loc: 0.017  time: 0.4000  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:36:30 d2.utils.events]: [0m eta: 0:17:09  iter: 419  total_loss: 0.245  loss_cls: 0.079  loss_box_reg: 0.097  loss_rpn_cls: 0.058  loss_rpn_loc: 0.014  time: 0.4002  data_time: 0.0079  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:36:38 d2.utils.events]: [0m eta: 0:17:02  iter: 439  total_loss: 0.252  loss_cls: 0.098  loss_box_reg: 0.092  loss_rpn_cls: 0.053  loss_rpn_loc: 0.012  time: 0.4002  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:36:46 d2.utils.events]: [0m eta: 0:16:54  iter: 459  total_loss: 0.260  loss_cls: 0.068  loss_box_reg: 0.095  loss_rpn_cls: 0.053  loss_rpn_loc: 0.018  time: 0.4002  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:36:54 d2.utils.events]: [0m eta: 0:16:46  iter: 479  total_loss: 0.222  loss_cls: 0.066  loss_box_reg: 0.092  loss_rpn_cls: 0.044  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:02 d2.utils.events]: [0m eta: 0:16:38  iter: 499  total_loss: 0.263  loss_cls: 0.083  loss_box_reg: 0.105  loss_rpn_cls: 0.056  loss_rpn_loc: 0.014  time: 0.4003  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:10 d2.utils.events]: [0m eta: 0:16:30  iter: 519  total_loss: 0.259  loss_cls: 0.076  loss_box_reg: 0.101  loss_rpn_cls: 0.055  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:18 d2.utils.events]: [0m eta: 0:16:22  iter: 539  total_loss: 0.242  loss_cls: 0.075  loss_box_reg: 0.091  loss_rpn_cls: 0.057  loss_rpn_loc: 0.017  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:26 d2.utils.events]: [0m eta: 0:16:14  iter: 559  total_loss: 0.267  loss_cls: 0.077  loss_box_reg: 0.103  loss_rpn_cls: 0.066  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:34 d2.utils.events]: [0m eta: 0:16:06  iter: 579  total_loss: 0.220  loss_cls: 0.069  loss_box_reg: 0.087  loss_rpn_cls: 0.045  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:42 d2.utils.events]: [0m eta: 0:15:58  iter: 599  total_loss: 0.236  loss_cls: 0.065  loss_box_reg: 0.083  loss_rpn_cls: 0.052  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0074  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:50 d2.utils.events]: [0m eta: 0:15:50  iter: 619  total_loss: 0.220  loss_cls: 0.068  loss_box_reg: 0.089  loss_rpn_cls: 0.046  loss_rpn_loc: 0.012  time: 0.4005  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:37:59 d2.utils.events]: [0m eta: 0:15:42  iter: 639  total_loss: 0.233  loss_cls: 0.076  loss_box_reg: 0.093  loss_rpn_cls: 0.052  loss_rpn_loc: 0.013  time: 0.4005  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:38:07 d2.utils.events]: [0m eta: 0:15:34  iter: 659  total_loss: 0.210  loss_cls: 0.067  loss_box_reg: 0.086  loss_rpn_cls: 0.042  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0073  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:38:15 d2.utils.events]: [0m eta: 0:15:26  iter: 679  total_loss: 0.250  loss_cls: 0.074  loss_box_reg: 0.094  loss_rpn_cls: 0.054  loss_rpn_loc: 0.013  time: 0.4005  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:38:23 d2.utils.events]: [0m eta: 0:15:19  iter: 699  total_loss: 0.237  loss_cls: 0.066  loss_box_reg: 0.080  loss_rpn_cls: 0.056  loss_rpn_loc: 0.020  time: 0.4005  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:38:31 d2.utils.events]: [0m eta: 0:15:11  iter: 719  total_loss: 0.224  loss_cls: 0.072  loss_box_reg: 0.091  loss_rpn_cls: 0.047  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:38:39 d2.utils.events]: [0m eta: 0:15:03  iter: 739  total_loss: 0.219  loss_cls: 0.059  loss_box_reg: 0.078  loss_rpn_cls: 0.056  loss_rpn_loc: 0.013  time: 0.4005  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:38:47 d2.utils.events]: [0m eta: 0:14:55  iter: 759  total_loss: 0.218  loss_cls: 0.063  loss_box_reg: 0.088  loss_rpn_cls: 0.054  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0066  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:38:55 d2.utils.events]: [0m eta: 0:14:47  iter: 779  total_loss: 0.225  loss_cls: 0.056  loss_box_reg: 0.085  loss_rpn_cls: 0.053  loss_rpn_loc: 0.018  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:03 d2.utils.events]: [0m eta: 0:14:39  iter: 799  total_loss: 0.212  loss_cls: 0.063  loss_box_reg: 0.082  loss_rpn_cls: 0.050  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:11 d2.utils.events]: [0m eta: 0:14:31  iter: 819  total_loss: 0.221  loss_cls: 0.053  loss_box_reg: 0.079  loss_rpn_cls: 0.066  loss_rpn_loc: 0.024  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:19 d2.utils.events]: [0m eta: 0:14:23  iter: 839  total_loss: 0.197  loss_cls: 0.059  loss_box_reg: 0.079  loss_rpn_cls: 0.048  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:27 d2.utils.events]: [0m eta: 0:14:15  iter: 859  total_loss: 0.222  loss_cls: 0.052  loss_box_reg: 0.079  loss_rpn_cls: 0.055  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:35 d2.utils.events]: [0m eta: 0:14:07  iter: 879  total_loss: 0.223  loss_cls: 0.066  loss_box_reg: 0.086  loss_rpn_cls: 0.052  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:43 d2.utils.events]: [0m eta: 0:13:58  iter: 899  total_loss: 0.195  loss_cls: 0.052  loss_box_reg: 0.078  loss_rpn_cls: 0.051  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:51 d2.utils.events]: [0m eta: 0:13:51  iter: 919  total_loss: 0.197  loss_cls: 0.058  loss_box_reg: 0.077  loss_rpn_cls: 0.045  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:39:59 d2.utils.events]: [0m eta: 0:13:43  iter: 939  total_loss: 0.214  loss_cls: 0.042  loss_box_reg: 0.075  loss_rpn_cls: 0.056  loss_rpn_loc: 0.018  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:40:07 d2.utils.events]: [0m eta: 0:13:35  iter: 959  total_loss: 0.198  loss_cls: 0.055  loss_box_reg: 0.079  loss_rpn_cls: 0.046  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:40:15 d2.utils.events]: [0m eta: 0:13:27  iter: 979  total_loss: 0.198  loss_cls: 0.057  loss_box_reg: 0.077  loss_rpn_cls: 0.049  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:40:23 d2.utils.events]: [0m eta: 0:13:19  iter: 999  total_loss: 0.202  loss_cls: 0.049  loss_box_reg: 0.083  loss_rpn_cls: 0.047  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:40:31 d2.utils.events]: [0m eta: 0:13:11  iter: 1019  total_loss: 0.183  loss_cls: 0.047  loss_box_reg: 0.076  loss_rpn_cls: 0.049  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0077  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:40:39 d2.utils.events]: [0m eta: 0:13:03  iter: 1039  total_loss: 0.217  loss_cls: 0.044  loss_box_reg: 0.075  loss_rpn_cls: 0.067  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0073  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:40:47 d2.utils.events]: [0m eta: 0:12:55  iter: 1059  total_loss: 0.206  loss_cls: 0.041  loss_box_reg: 0.075  loss_rpn_cls: 0.056  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:40:55 d2.utils.events]: [0m eta: 0:12:47  iter: 1079  total_loss: 0.183  loss_cls: 0.050  loss_box_reg: 0.073  loss_rpn_cls: 0.047  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:03 d2.utils.events]: [0m eta: 0:12:39  iter: 1099  total_loss: 0.184  loss_cls: 0.039  loss_box_reg: 0.069  loss_rpn_cls: 0.052  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:11 d2.utils.events]: [0m eta: 0:12:31  iter: 1119  total_loss: 0.183  loss_cls: 0.039  loss_box_reg: 0.076  loss_rpn_cls: 0.052  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:19 d2.utils.events]: [0m eta: 0:12:23  iter: 1139  total_loss: 0.220  loss_cls: 0.056  loss_box_reg: 0.071  loss_rpn_cls: 0.058  loss_rpn_loc: 0.018  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:27 d2.utils.events]: [0m eta: 0:12:15  iter: 1159  total_loss: 0.172  loss_cls: 0.039  loss_box_reg: 0.070  loss_rpn_cls: 0.046  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:35 d2.utils.events]: [0m eta: 0:12:07  iter: 1179  total_loss: 0.190  loss_cls: 0.036  loss_box_reg: 0.076  loss_rpn_cls: 0.058  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:43 d2.utils.events]: [0m eta: 0:11:59  iter: 1199  total_loss: 0.198  loss_cls: 0.047  loss_box_reg: 0.068  loss_rpn_cls: 0.055  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:51 d2.utils.events]: [0m eta: 0:11:51  iter: 1219  total_loss: 0.172  loss_cls: 0.041  loss_box_reg: 0.065  loss_rpn_cls: 0.046  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:41:59 d2.utils.events]: [0m eta: 0:11:43  iter: 1239  total_loss: 0.197  loss_cls: 0.048  loss_box_reg: 0.071  loss_rpn_cls: 0.055  loss_rpn_loc: 0.020  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:42:07 d2.utils.events]: [0m eta: 0:11:35  iter: 1259  total_loss: 0.198  loss_cls: 0.048  loss_box_reg: 0.064  loss_rpn_cls: 0.056  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:42:15 d2.utils.events]: [0m eta: 0:11:27  iter: 1279  total_loss: 0.199  loss_cls: 0.046  loss_box_reg: 0.069  loss_rpn_cls: 0.049  loss_rpn_loc: 0.017  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:42:23 d2.utils.events]: [0m eta: 0:11:19  iter: 1299  total_loss: 0.177  loss_cls: 0.044  loss_box_reg: 0.069  loss_rpn_cls: 0.047  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:42:31 d2.utils.events]: [0m eta: 0:11:11  iter: 1319  total_loss: 0.176  loss_cls: 0.042  loss_box_reg: 0.067  loss_rpn_cls: 0.046  loss_rpn_loc: 0.008  time: 0.4004  data_time: 0.0073  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:42:39 d2.utils.events]: [0m eta: 0:11:03  iter: 1339  total_loss: 0.188  loss_cls: 0.051  loss_box_reg: 0.066  loss_rpn_cls: 0.048  loss_rpn_loc: 0.015  time: 0.4003  data_time: 0.0073  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:42:47 d2.utils.events]: [0m eta: 0:10:55  iter: 1359  total_loss: 0.180  loss_cls: 0.050  loss_box_reg: 0.074  loss_rpn_cls: 0.045  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:42:55 d2.utils.events]: [0m eta: 0:10:47  iter: 1379  total_loss: 0.182  loss_cls: 0.036  loss_box_reg: 0.059  loss_rpn_cls: 0.056  loss_rpn_loc: 0.018  time: 0.4004  data_time: 0.0073  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:03 d2.utils.events]: [0m eta: 0:10:39  iter: 1399  total_loss: 0.174  loss_cls: 0.035  loss_box_reg: 0.065  loss_rpn_cls: 0.052  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:11 d2.utils.events]: [0m eta: 0:10:31  iter: 1419  total_loss: 0.188  loss_cls: 0.042  loss_box_reg: 0.065  loss_rpn_cls: 0.056  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:19 d2.utils.events]: [0m eta: 0:10:23  iter: 1439  total_loss: 0.171  loss_cls: 0.042  loss_box_reg: 0.065  loss_rpn_cls: 0.040  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:27 d2.utils.events]: [0m eta: 0:10:15  iter: 1459  total_loss: 0.178  loss_cls: 0.042  loss_box_reg: 0.070  loss_rpn_cls: 0.052  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:35 d2.utils.events]: [0m eta: 0:10:07  iter: 1479  total_loss: 0.156  loss_cls: 0.038  loss_box_reg: 0.066  loss_rpn_cls: 0.039  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:43 d2.utils.events]: [0m eta: 0:09:59  iter: 1499  total_loss: 0.179  loss_cls: 0.039  loss_box_reg: 0.067  loss_rpn_cls: 0.046  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:51 d2.utils.events]: [0m eta: 0:09:51  iter: 1519  total_loss: 0.158  loss_cls: 0.034  loss_box_reg: 0.058  loss_rpn_cls: 0.032  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0074  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:43:59 d2.utils.events]: [0m eta: 0:09:43  iter: 1539  total_loss: 0.182  loss_cls: 0.040  loss_box_reg: 0.066  loss_rpn_cls: 0.058  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0065  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:44:07 d2.utils.events]: [0m eta: 0:09:35  iter: 1559  total_loss: 0.174  loss_cls: 0.039  loss_box_reg: 0.062  loss_rpn_cls: 0.052  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0075  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:44:15 d2.utils.events]: [0m eta: 0:09:27  iter: 1579  total_loss: 0.166  loss_cls: 0.041  loss_box_reg: 0.064  loss_rpn_cls: 0.053  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:44:23 d2.utils.events]: [0m eta: 0:09:19  iter: 1599  total_loss: 0.155  loss_cls: 0.040  loss_box_reg: 0.063  loss_rpn_cls: 0.046  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:44:31 d2.utils.events]: [0m eta: 0:09:11  iter: 1619  total_loss: 0.159  loss_cls: 0.040  loss_box_reg: 0.062  loss_rpn_cls: 0.044  loss_rpn_loc: 0.009  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:44:39 d2.utils.events]: [0m eta: 0:09:03  iter: 1639  total_loss: 0.178  loss_cls: 0.043  loss_box_reg: 0.061  loss_rpn_cls: 0.042  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:44:47 d2.utils.events]: [0m eta: 0:08:55  iter: 1659  total_loss: 0.172  loss_cls: 0.038  loss_box_reg: 0.065  loss_rpn_cls: 0.043  loss_rpn_loc: 0.019  time: 0.4004  data_time: 0.0074  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:44:55 d2.utils.events]: [0m eta: 0:08:47  iter: 1679  total_loss: 0.169  loss_cls: 0.042  loss_box_reg: 0.063  loss_rpn_cls: 0.045  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:03 d2.utils.events]: [0m eta: 0:08:39  iter: 1699  total_loss: 0.169  loss_cls: 0.042  loss_box_reg: 0.064  loss_rpn_cls: 0.043  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:11 d2.utils.events]: [0m eta: 0:08:31  iter: 1719  total_loss: 0.162  loss_cls: 0.032  loss_box_reg: 0.063  loss_rpn_cls: 0.047  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:19 d2.utils.events]: [0m eta: 0:08:23  iter: 1739  total_loss: 0.178  loss_cls: 0.051  loss_box_reg: 0.062  loss_rpn_cls: 0.049  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:27 d2.utils.events]: [0m eta: 0:08:15  iter: 1759  total_loss: 0.145  loss_cls: 0.035  loss_box_reg: 0.061  loss_rpn_cls: 0.039  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:35 d2.utils.events]: [0m eta: 0:08:07  iter: 1779  total_loss: 0.169  loss_cls: 0.034  loss_box_reg: 0.059  loss_rpn_cls: 0.045  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0070  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:43 d2.utils.events]: [0m eta: 0:07:59  iter: 1799  total_loss: 0.170  loss_cls: 0.040  loss_box_reg: 0.061  loss_rpn_cls: 0.047  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0078  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:51 d2.utils.events]: [0m eta: 0:07:51  iter: 1819  total_loss: 0.160  loss_cls: 0.033  loss_box_reg: 0.055  loss_rpn_cls: 0.046  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:45:59 d2.utils.events]: [0m eta: 0:07:43  iter: 1839  total_loss: 0.177  loss_cls: 0.033  loss_box_reg: 0.067  loss_rpn_cls: 0.050  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:46:07 d2.utils.events]: [0m eta: 0:07:35  iter: 1859  total_loss: 0.149  loss_cls: 0.032  loss_box_reg: 0.057  loss_rpn_cls: 0.042  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0069  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:46:15 d2.utils.events]: [0m eta: 0:07:27  iter: 1879  total_loss: 0.173  loss_cls: 0.042  loss_box_reg: 0.061  loss_rpn_cls: 0.047  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:46:23 d2.utils.events]: [0m eta: 0:07:19  iter: 1899  total_loss: 0.156  loss_cls: 0.038  loss_box_reg: 0.060  loss_rpn_cls: 0.041  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0071  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:46:31 d2.utils.events]: [0m eta: 0:07:11  iter: 1919  total_loss: 0.165  loss_cls: 0.036  loss_box_reg: 0.056  loss_rpn_cls: 0.045  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:46:39 d2.utils.events]: [0m eta: 0:07:03  iter: 1939  total_loss: 0.163  loss_cls: 0.042  loss_box_reg: 0.064  loss_rpn_cls: 0.040  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0074  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:46:47 d2.utils.events]: [0m eta: 0:06:55  iter: 1959  total_loss: 0.156  loss_cls: 0.036  loss_box_reg: 0.063  loss_rpn_cls: 0.050  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0067  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:46:55 d2.utils.events]: [0m eta: 0:06:47  iter: 1979  total_loss: 0.140  loss_cls: 0.032  loss_box_reg: 0.055  loss_rpn_cls: 0.039  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0068  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:47:04 d2.utils.events]: [0m eta: 0:06:39  iter: 1999  total_loss: 0.149  loss_cls: 0.042  loss_box_reg: 0.056  loss_rpn_cls: 0.039  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0072  lr: 0.001000  max_mem: 2017M
[32m[08/08 17:47:12 d2.utils.events]: [0m eta: 0:06:31  iter: 2019  total_loss: 0.147  loss_cls: 0.036  loss_box_reg: 0.059  loss_rpn_cls: 0.039  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0066  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:47:20 d2.utils.events]: [0m eta: 0:06:23  iter: 2039  total_loss: 0.180  loss_cls: 0.039  loss_box_reg: 0.056  loss_rpn_cls: 0.058  loss_rpn_loc: 0.018  time: 0.4004  data_time: 0.0067  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:47:28 d2.utils.events]: [0m eta: 0:06:15  iter: 2059  total_loss: 0.152  loss_cls: 0.037  loss_box_reg: 0.058  loss_rpn_cls: 0.041  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:47:36 d2.utils.events]: [0m eta: 0:06:07  iter: 2079  total_loss: 0.161  loss_cls: 0.037  loss_box_reg: 0.060  loss_rpn_cls: 0.045  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0070  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:47:44 d2.utils.events]: [0m eta: 0:05:59  iter: 2099  total_loss: 0.166  loss_cls: 0.032  loss_box_reg: 0.056  loss_rpn_cls: 0.060  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:47:52 d2.utils.events]: [0m eta: 0:05:51  iter: 2119  total_loss: 0.155  loss_cls: 0.028  loss_box_reg: 0.053  loss_rpn_cls: 0.044  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:00 d2.utils.events]: [0m eta: 0:05:43  iter: 2139  total_loss: 0.161  loss_cls: 0.037  loss_box_reg: 0.056  loss_rpn_cls: 0.049  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0070  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:08 d2.utils.events]: [0m eta: 0:05:35  iter: 2159  total_loss: 0.140  loss_cls: 0.032  loss_box_reg: 0.058  loss_rpn_cls: 0.039  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:16 d2.utils.events]: [0m eta: 0:05:27  iter: 2179  total_loss: 0.163  loss_cls: 0.031  loss_box_reg: 0.054  loss_rpn_cls: 0.049  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0085  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:24 d2.utils.events]: [0m eta: 0:05:19  iter: 2199  total_loss: 0.138  loss_cls: 0.032  loss_box_reg: 0.055  loss_rpn_cls: 0.047  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:32 d2.utils.events]: [0m eta: 0:05:11  iter: 2219  total_loss: 0.134  loss_cls: 0.027  loss_box_reg: 0.053  loss_rpn_cls: 0.045  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0071  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:40 d2.utils.events]: [0m eta: 0:05:03  iter: 2239  total_loss: 0.148  loss_cls: 0.028  loss_box_reg: 0.057  loss_rpn_cls: 0.045  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0067  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:48 d2.utils.events]: [0m eta: 0:04:55  iter: 2259  total_loss: 0.151  loss_cls: 0.030  loss_box_reg: 0.058  loss_rpn_cls: 0.036  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0076  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:48:56 d2.utils.events]: [0m eta: 0:04:47  iter: 2279  total_loss: 0.152  loss_cls: 0.029  loss_box_reg: 0.054  loss_rpn_cls: 0.057  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0067  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:49:04 d2.utils.events]: [0m eta: 0:04:39  iter: 2299  total_loss: 0.146  loss_cls: 0.035  loss_box_reg: 0.055  loss_rpn_cls: 0.043  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0074  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:49:12 d2.utils.events]: [0m eta: 0:04:31  iter: 2319  total_loss: 0.152  loss_cls: 0.029  loss_box_reg: 0.056  loss_rpn_cls: 0.042  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0070  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:49:20 d2.utils.events]: [0m eta: 0:04:23  iter: 2339  total_loss: 0.135  loss_cls: 0.028  loss_box_reg: 0.054  loss_rpn_cls: 0.047  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:49:28 d2.utils.events]: [0m eta: 0:04:15  iter: 2359  total_loss: 0.143  loss_cls: 0.031  loss_box_reg: 0.049  loss_rpn_cls: 0.048  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:49:36 d2.utils.events]: [0m eta: 0:04:07  iter: 2379  total_loss: 0.163  loss_cls: 0.034  loss_box_reg: 0.059  loss_rpn_cls: 0.044  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0071  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:49:44 d2.utils.events]: [0m eta: 0:03:59  iter: 2399  total_loss: 0.156  loss_cls: 0.028  loss_box_reg: 0.057  loss_rpn_cls: 0.054  loss_rpn_loc: 0.016  time: 0.4005  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:49:52 d2.utils.events]: [0m eta: 0:03:51  iter: 2419  total_loss: 0.153  loss_cls: 0.032  loss_box_reg: 0.057  loss_rpn_cls: 0.039  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:00 d2.utils.events]: [0m eta: 0:03:43  iter: 2439  total_loss: 0.137  loss_cls: 0.024  loss_box_reg: 0.057  loss_rpn_cls: 0.041  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0071  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:08 d2.utils.events]: [0m eta: 0:03:36  iter: 2459  total_loss: 0.156  loss_cls: 0.031  loss_box_reg: 0.057  loss_rpn_cls: 0.043  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0072  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:16 d2.utils.events]: [0m eta: 0:03:28  iter: 2479  total_loss: 0.139  loss_cls: 0.032  loss_box_reg: 0.054  loss_rpn_cls: 0.043  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0076  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:24 d2.utils.events]: [0m eta: 0:03:20  iter: 2499  total_loss: 0.151  loss_cls: 0.033  loss_box_reg: 0.053  loss_rpn_cls: 0.047  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:32 d2.utils.events]: [0m eta: 0:03:12  iter: 2519  total_loss: 0.136  loss_cls: 0.027  loss_box_reg: 0.053  loss_rpn_cls: 0.041  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:40 d2.utils.events]: [0m eta: 0:03:04  iter: 2539  total_loss: 0.162  loss_cls: 0.025  loss_box_reg: 0.056  loss_rpn_cls: 0.053  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:48 d2.utils.events]: [0m eta: 0:02:56  iter: 2559  total_loss: 0.159  loss_cls: 0.037  loss_box_reg: 0.064  loss_rpn_cls: 0.042  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:50:56 d2.utils.events]: [0m eta: 0:02:48  iter: 2579  total_loss: 0.145  loss_cls: 0.033  loss_box_reg: 0.053  loss_rpn_cls: 0.043  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:51:04 d2.utils.events]: [0m eta: 0:02:40  iter: 2599  total_loss: 0.139  loss_cls: 0.032  loss_box_reg: 0.055  loss_rpn_cls: 0.044  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0067  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:51:12 d2.utils.events]: [0m eta: 0:02:32  iter: 2619  total_loss: 0.149  loss_cls: 0.032  loss_box_reg: 0.055  loss_rpn_cls: 0.037  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0066  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:51:20 d2.utils.events]: [0m eta: 0:02:24  iter: 2639  total_loss: 0.145  loss_cls: 0.030  loss_box_reg: 0.056  loss_rpn_cls: 0.046  loss_rpn_loc: 0.016  time: 0.4004  data_time: 0.0070  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:51:28 d2.utils.events]: [0m eta: 0:02:16  iter: 2659  total_loss: 0.164  loss_cls: 0.027  loss_box_reg: 0.054  loss_rpn_cls: 0.049  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0071  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:51:36 d2.utils.events]: [0m eta: 0:02:08  iter: 2679  total_loss: 0.158  loss_cls: 0.032  loss_box_reg: 0.056  loss_rpn_cls: 0.049  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0074  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:51:44 d2.utils.events]: [0m eta: 0:02:00  iter: 2699  total_loss: 0.134  loss_cls: 0.025  loss_box_reg: 0.053  loss_rpn_cls: 0.043  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0074  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:51:52 d2.utils.events]: [0m eta: 0:01:52  iter: 2719  total_loss: 0.155  loss_cls: 0.038  loss_box_reg: 0.054  loss_rpn_cls: 0.048  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0067  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:00 d2.utils.events]: [0m eta: 0:01:44  iter: 2739  total_loss: 0.136  loss_cls: 0.025  loss_box_reg: 0.050  loss_rpn_cls: 0.043  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0070  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:08 d2.utils.events]: [0m eta: 0:01:36  iter: 2759  total_loss: 0.150  loss_cls: 0.024  loss_box_reg: 0.054  loss_rpn_cls: 0.052  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0072  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:16 d2.utils.events]: [0m eta: 0:01:28  iter: 2779  total_loss: 0.146  loss_cls: 0.030  loss_box_reg: 0.058  loss_rpn_cls: 0.041  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0067  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:24 d2.utils.events]: [0m eta: 0:01:20  iter: 2799  total_loss: 0.152  loss_cls: 0.027  loss_box_reg: 0.054  loss_rpn_cls: 0.045  loss_rpn_loc: 0.012  time: 0.4004  data_time: 0.0076  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:32 d2.utils.events]: [0m eta: 0:01:12  iter: 2819  total_loss: 0.149  loss_cls: 0.031  loss_box_reg: 0.052  loss_rpn_cls: 0.045  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:40 d2.utils.events]: [0m eta: 0:01:04  iter: 2839  total_loss: 0.148  loss_cls: 0.029  loss_box_reg: 0.058  loss_rpn_cls: 0.045  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:48 d2.utils.events]: [0m eta: 0:00:56  iter: 2859  total_loss: 0.160  loss_cls: 0.031  loss_box_reg: 0.055  loss_rpn_cls: 0.062  loss_rpn_loc: 0.017  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:52:56 d2.utils.events]: [0m eta: 0:00:48  iter: 2879  total_loss: 0.146  loss_cls: 0.027  loss_box_reg: 0.051  loss_rpn_cls: 0.038  loss_rpn_loc: 0.010  time: 0.4004  data_time: 0.0067  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:53:04 d2.utils.events]: [0m eta: 0:00:40  iter: 2899  total_loss: 0.152  loss_cls: 0.030  loss_box_reg: 0.054  loss_rpn_cls: 0.042  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0069  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:53:12 d2.utils.events]: [0m eta: 0:00:32  iter: 2919  total_loss: 0.152  loss_cls: 0.029  loss_box_reg: 0.055  loss_rpn_cls: 0.046  loss_rpn_loc: 0.014  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:53:20 d2.utils.events]: [0m eta: 0:00:24  iter: 2939  total_loss: 0.136  loss_cls: 0.029  loss_box_reg: 0.055  loss_rpn_cls: 0.038  loss_rpn_loc: 0.011  time: 0.4004  data_time: 0.0074  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:53:28 d2.utils.events]: [0m eta: 0:00:16  iter: 2959  total_loss: 0.150  loss_cls: 0.029  loss_box_reg: 0.050  loss_rpn_cls: 0.044  loss_rpn_loc: 0.015  time: 0.4004  data_time: 0.0071  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:53:36 d2.utils.events]: [0m eta: 0:00:08  iter: 2979  total_loss: 0.137  loss_cls: 0.022  loss_box_reg: 0.060  loss_rpn_cls: 0.043  loss_rpn_loc: 0.013  time: 0.4004  data_time: 0.0068  lr: 0.000100  max_mem: 2017M
[32m[08/08 17:53:44 fvcore.common.checkpoint]: [0mSaving checkpoint to ./output/fsod/finetune_dir/R_50_C4_1x/model_final.pth
[32m[08/08 17:53:46 d2.data.datasets.coco]: [0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[32m[08/08 17:53:46 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[32m[08/08 17:53:46 d2.data.common]: [0mSerializing 5000 elements to byte tensors and concatenating them all ...
[32m[08/08 17:53:46 d2.data.common]: [0mSerialized dataset takes 19.10 MiB
[32m[08/08 17:53:46 d2.data.dataset_mapper]: [0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1000, sample_style='choice')]
[32m[08/08 17:53:47 d2.evaluation.evaluator]: [0mStart inference on 1250 images
[4m[5m[31mERROR[0m [32m[08/08 17:54:07 d2.engine.train_loop]: [0mException during training:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 131, in train
    self.after_step()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 152, in after_step
    h.after_step()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/hooks.py", line 349, in after_step
    self._do_eval()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/hooks.py", line 323, in _do_eval
    results = self._func()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 351, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 515, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/opt/conda/lib/python3.7/site-packages/detectron2/evaluation/evaluator.py", line 141, in inference_on_dataset
    outputs = model(inputs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 458, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/fanqi/code/fsod/2-fsod/fewx/modeling/fsod/fsod_rcnn.py", line 125, in forward
    self.init_model()
  File "/home/fanqi/code/fsod/2-fsod/fewx/modeling/fsod/fsod_rcnn.py", line 303, in init_model
    assert False
AssertionError
[32m[08/08 17:54:07 d2.engine.hooks]: [0mOverall training speed: 2997 iterations in 0:20:00 (0.4005 s / it)
[32m[08/08 17:54:07 d2.engine.hooks]: [0mTotal training time: 0:20:24 (0:00:23 on hooks)
/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
/opt/conda/lib/python3.7/site-packages/torch/storage.py:34: FutureWarning: pickle support for Storage will be removed in 1.5. Use `torch.save` instead
  warnings.warn("pickle support for Storage will be removed in 1.5. Use `torch.save` instead", FutureWarning)
Traceback (most recent call last):
  File "fsod_train_net.py", line 118, in <module>
    args=(args,),
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/launch.py", line 59, in launch
    daemon=False,
  File "/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 200, in spawn
    return start_processes(fn, args, nprocs, join, daemon, start_method='spawn')
  File "/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 158, in start_processes
    while not context.join():
  File "/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 119, in join
    raise Exception(msg)
Exception: 

-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File "/opt/conda/lib/python3.7/site-packages/torch/multiprocessing/spawn.py", line 20, in _wrap
    fn(i, *args)
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/launch.py", line 94, in _distributed_worker
    main_func(*args)
  File "/home/fanqi/code/fsod/2-fsod/fsod_train_net.py", line 106, in main
    return trainer.train()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 398, in train
    super().train(self.start_iter, self.max_iter)
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 131, in train
    self.after_step()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/train_loop.py", line 152, in after_step
    h.after_step()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/hooks.py", line 349, in after_step
    self._do_eval()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/hooks.py", line 323, in _do_eval
    results = self._func()
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 351, in test_and_save_results
    self._last_eval_results = self.test(self.cfg, self.model)
  File "/opt/conda/lib/python3.7/site-packages/detectron2/engine/defaults.py", line 515, in test
    results_i = inference_on_dataset(model, data_loader, evaluator)
  File "/opt/conda/lib/python3.7/site-packages/detectron2/evaluation/evaluator.py", line 141, in inference_on_dataset
    outputs = model(inputs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/parallel/distributed.py", line 458, in forward
    output = self.module(*inputs[0], **kwargs[0])
  File "/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py", line 550, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/fanqi/code/fsod/2-fsod/fewx/modeling/fsod/fsod_rcnn.py", line 125, in forward
    self.init_model()
  File "/home/fanqi/code/fsod/2-fsod/fewx/modeling/fsod/fsod_rcnn.py", line 303, in init_model
    assert False
AssertionError

